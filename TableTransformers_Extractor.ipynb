{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TableTransformer - Dataset Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageDraw, ImageTk\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "from transformers import AutoModelForObjectDetection, TableTransformerForObjectDetection\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# CUDA Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Detection and Processing\n",
    "\n",
    "Function: box_cxcywh_to_xyxy(x) :\n",
    "Converts bounding boxes from center coordinates and size (cx, cy, w, h) format to corner coordinates (x1, y1, x2, y2) format\n",
    "\n",
    "Function: rescale_bboxes(out_bbox, size) :\n",
    "Rescales bounding boxes to the size of the image.\n",
    "\n",
    "Function: outputs_to_objects(outputs, img_size, id2label) :\n",
    "Converts model outputs to a list of detected objects with labels, scores, and bounding boxes.\n",
    "\n",
    "Function: fig2img(fig) :\n",
    "Converts a Matplotlib figure to a PIL Image.\n",
    "\n",
    "Function: visualize_detected_tables(img, det_tables, out_path=None) :\n",
    "Visualizes detected tables on an image, highlighting them with different colors based on their type.\n",
    "\n",
    "Function: objects_to_crops(img, tokens, objects, class_thresholds, padding=10) :\n",
    "Processes detected bounding boxes into cropped table images and their respective tokens.\n",
    "\n",
    "Function: get_cell_coordinates_by_row(table_data) :\n",
    "Extracts cell coordinates from table data, organizing them by rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxResize(object):\n",
    "    def __init__(self, max_size=800):\n",
    "        self.max_size = max_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "        width, height = image.size\n",
    "        current_max_size = max(width, height)\n",
    "        scale = self.max_size / current_max_size\n",
    "        resized_image = image.resize(\n",
    "            (int(round(scale * width)), int(round(scale * height)))\n",
    "        )\n",
    "\n",
    "        return resized_image\n",
    "\n",
    "\n",
    "# for output bounding box post-processing\n",
    "def box_cxcywh_to_xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(-1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h), (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=1)\n",
    "\n",
    "\n",
    "def rescale_bboxes(out_bbox, size):\n",
    "    img_w, img_h = size\n",
    "    b = box_cxcywh_to_xyxy(out_bbox)\n",
    "    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n",
    "    return b\n",
    "\n",
    "\n",
    "# Object detection\n",
    "def outputs_to_objects(outputs, img_size, id2label):\n",
    "    m = outputs.logits.softmax(-1).max(-1)\n",
    "    pred_labels = list(m.indices.detach().cpu().numpy())[0]\n",
    "    pred_scores = list(m.values.detach().cpu().numpy())[0]\n",
    "    pred_bboxes = outputs[\"pred_boxes\"].detach().cpu()[0]\n",
    "    pred_bboxes = [elem.tolist() for elem in rescale_bboxes(pred_bboxes, img_size)]\n",
    "\n",
    "    objects = []\n",
    "    for label, score, bbox in zip(pred_labels, pred_scores, pred_bboxes):\n",
    "        class_label = id2label[int(label)]\n",
    "        if not class_label == \"no object\":\n",
    "            objects.append(\n",
    "                {\n",
    "                    \"label\": class_label,\n",
    "                    \"score\": float(score),\n",
    "                    \"bbox\": [float(elem) for elem in bbox],\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return objects\n",
    "\n",
    "\n",
    "def fig2img(fig):\n",
    "    \"\"\"Convert a Matplotlib figure to a PIL Image and return it\"\"\"\n",
    "    import io\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf)\n",
    "    buf.seek(0)\n",
    "    img = Image.open(buf)\n",
    "    return img\n",
    "\n",
    "\n",
    "def visualize_detected_tables(img, det_tables, out_path=None):\n",
    "    plt.imshow(img, interpolation=\"lanczos\")\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(20, 20)\n",
    "    ax = plt.gca()\n",
    "\n",
    "    for det_table in det_tables:\n",
    "        bbox = det_table[\"bbox\"]\n",
    "\n",
    "        # Extend the bottom edge of the bounding box\n",
    "        extend_height = (bbox[3] - bbox[1]) * 0.05\n",
    "        bbox[3] += extend_height\n",
    "\n",
    "        # Extend the top edge of the bounding box\n",
    "        bbox[1] -= extend_height\n",
    "\n",
    "        if det_table[\"label\"] == \"table\":\n",
    "            facecolor = (1, 0, 0.45)\n",
    "            edgecolor = (1, 0, 0.45)\n",
    "            alpha = 0.3\n",
    "            linewidth = 2\n",
    "            hatch = \"//////\"\n",
    "        elif det_table[\"label\"] == \"table rotated\":\n",
    "            facecolor = (0.95, 0.6, 0.1)\n",
    "            edgecolor = (0.95, 0.6, 0.1)\n",
    "            alpha = 0.3\n",
    "            linewidth = 2\n",
    "            hatch = \"//////\"\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        rect = patches.Rectangle(\n",
    "            bbox[:2],\n",
    "            bbox[2] - bbox[0],\n",
    "            bbox[3] - bbox[1],\n",
    "            linewidth=linewidth,\n",
    "            edgecolor=\"none\",\n",
    "            facecolor=facecolor,\n",
    "            alpha=0.1,\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        rect = patches.Rectangle(\n",
    "            bbox[:2],\n",
    "            bbox[2] - bbox[0],\n",
    "            bbox[3] - bbox[1],\n",
    "            linewidth=linewidth,\n",
    "            edgecolor=edgecolor,\n",
    "            facecolor=\"none\",\n",
    "            linestyle=\"-\",\n",
    "            alpha=alpha,\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        rect = patches.Rectangle(\n",
    "            bbox[:2],\n",
    "            bbox[2] - bbox[0],\n",
    "            bbox[3] - bbox[1],\n",
    "            linewidth=0,\n",
    "            edgecolor=edgecolor,\n",
    "            facecolor=\"none\",\n",
    "            linestyle=\"-\",\n",
    "            hatch=hatch,\n",
    "            alpha=0.2,\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "\n",
    "    legend_elements = [\n",
    "        Patch(\n",
    "            facecolor=(1, 0, 0.45),\n",
    "            edgecolor=(1, 0, 0.45),\n",
    "            label=\"Table\",\n",
    "            hatch=\"//////\",\n",
    "            alpha=0.3,\n",
    "        ),\n",
    "        Patch(\n",
    "            facecolor=(0.95, 0.6, 0.1),\n",
    "            edgecolor=(0.95, 0.6, 0.1),\n",
    "            label=\"Table (rotated)\",\n",
    "            hatch=\"//////\",\n",
    "            alpha=0.3,\n",
    "        ),\n",
    "    ]\n",
    "    plt.legend(\n",
    "        handles=legend_elements,\n",
    "        bbox_to_anchor=(0.5, -0.02),\n",
    "        loc=\"upper center\",\n",
    "        borderaxespad=0,\n",
    "        fontsize=10,\n",
    "        ncol=2,\n",
    "    )\n",
    "    plt.gcf().set_size_inches(10, 10)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    if out_path is not None:\n",
    "        plt.savefig(out_path, bbox_inches=\"tight\", dpi=150)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def objects_to_crops(img, tokens, objects, class_thresholds, padding=10):\n",
    "    \"\"\"\n",
    "    Process the bounding boxes produced by the table detection model into\n",
    "    cropped table images and cropped tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    table_crops = []\n",
    "    for obj in objects:\n",
    "        if obj[\"score\"] < class_thresholds[obj[\"label\"]]:\n",
    "            continue\n",
    "\n",
    "        cropped_table = {}\n",
    "\n",
    "        bbox = obj[\"bbox\"]\n",
    "        bbox = [\n",
    "            bbox[0] - padding,\n",
    "            bbox[1] - padding,\n",
    "            bbox[2] + padding,\n",
    "            bbox[3] + padding,\n",
    "        ]\n",
    "\n",
    "        cropped_img = img.crop(bbox)\n",
    "\n",
    "        table_tokens = [token for token in tokens if iob(token[\"bbox\"], bbox) >= 0.5]\n",
    "        for token in table_tokens:\n",
    "            token[\"bbox\"] = [\n",
    "                token[\"bbox\"][0] - bbox[0],\n",
    "                token[\"bbox\"][1] - bbox[1],\n",
    "                token[\"bbox\"][2] - bbox[0],\n",
    "                token[\"bbox\"][3] - bbox[1],\n",
    "            ]\n",
    "\n",
    "        # If table is predicted to be rotated, rotate cropped image and tokens/words:\n",
    "        if obj[\"label\"] == \"table rotated\":\n",
    "            cropped_img = cropped_img.rotate(270, expand=True)\n",
    "            for token in table_tokens:\n",
    "                bbox = token[\"bbox\"]\n",
    "                bbox = [\n",
    "                    cropped_img.size[0] - bbox[3] - 1,\n",
    "                    bbox[0],\n",
    "                    cropped_img.size[0] - bbox[1] - 1,\n",
    "                    bbox[2],\n",
    "                ]\n",
    "                token[\"bbox\"] = bbox\n",
    "\n",
    "        cropped_table[\"image\"] = cropped_img\n",
    "        cropped_table[\"tokens\"] = table_tokens\n",
    "\n",
    "        table_crops.append(cropped_table)\n",
    "\n",
    "    return table_crops\n",
    "\n",
    "\n",
    "def get_cell_coordinates_by_row(table_data):\n",
    "    # Extract rows and columns\n",
    "    rows = [entry for entry in table_data if entry[\"label\"] == \"table row\"]\n",
    "    columns = [entry for entry in table_data if entry[\"label\"] == \"table column\"]\n",
    "\n",
    "    # Sort rows and columns by their Y and X coordinates, respectively\n",
    "    rows.sort(key=lambda x: x[\"bbox\"][1])\n",
    "    columns.sort(key=lambda x: x[\"bbox\"][0])\n",
    "\n",
    "    # Function to find cell coordinates\n",
    "    def find_cell_coordinates(row, column):\n",
    "        cell_bbox = [\n",
    "            column[\"bbox\"][0],\n",
    "            row[\"bbox\"][1],\n",
    "            column[\"bbox\"][2],\n",
    "            row[\"bbox\"][3],\n",
    "        ]\n",
    "        return cell_bbox\n",
    "\n",
    "    # Generate cell coordinates and count cells in each row\n",
    "    cell_coordinates = []\n",
    "\n",
    "    for row in rows:\n",
    "        row_cells = []\n",
    "        for column in columns:\n",
    "            cell_bbox = find_cell_coordinates(row, column)\n",
    "            row_cells.append({\"column\": column[\"bbox\"], \"cell\": cell_bbox})\n",
    "\n",
    "        # Sort cells in the row by X coordinate\n",
    "        row_cells.sort(key=lambda x: x[\"column\"][0])\n",
    "\n",
    "        # Append row information to cell_coordinates\n",
    "        cell_coordinates.append(\n",
    "            {\"row\": row[\"bbox\"], \"cells\": row_cells, \"cell_count\": len(row_cells)}\n",
    "        )\n",
    "\n",
    "    # Sort rows from top to bottom\n",
    "    cell_coordinates.sort(key=lambda x: x[\"row\"][1])\n",
    "\n",
    "    return cell_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Detection Model\n",
    "Loads a pre-trained object detection model specifically designed for table detection.\n",
    "\n",
    "### Table Structure Recognition Model\n",
    "Loads a pre-trained model for recognizing table structures, and applies necessary transformations to the input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model config:  {0: 'table', 1: 'table rotated'}\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForObjectDetection.from_pretrained(\n",
    "    \"microsoft/table-transformer-detection\", revision=\"no_timm\"\n",
    ")\n",
    "\n",
    "print(\"Model config: \", model.config.id2label)\n",
    "\n",
    "detection_transform = transforms.Compose(\n",
    "    [\n",
    "        MaxResize(800),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# update id2label to include \"no object\"\n",
    "id2label = model.config.id2label\n",
    "id2label[len(model.config.id2label)] = \"no object\"\n",
    "\n",
    "\n",
    "#  Structure Model\n",
    "structure_model = TableTransformerForObjectDetection.from_pretrained(\n",
    "    \"microsoft/table-structure-recognition-v1.1-all\"\n",
    ")\n",
    "structure_model.to(\"cpu\")\n",
    "\n",
    "structure_transform = transforms.Compose(\n",
    "    [\n",
    "        MaxResize(1000),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# update id2label to include \"no object\"\n",
    "structure_id2label = structure_model.config.id2label\n",
    "structure_id2label[len(structure_id2label)] = \"no object\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GUI for Cell Classification\n",
    "#### Function: create_classification_gui(cell_crops, file_name_without_extension) :\n",
    "Creates a GUI for classifying cell images into three categories: \"true\", \"false\", and \"none\". The classified images are converted to grayscale and saved in corresponding directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classification_gui(cell_crops, file_name_without_extension):\n",
    "    dataset_path = pathlib.Path(\"dataset/train\")\n",
    "    sub_paths = [\"true\", \"false\", \"none\"]\n",
    "\n",
    "    for sub_path in sub_paths:\n",
    "        path = dataset_path / sub_path\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def save_classified_image(image_array, classification, cell_number):\n",
    "        new_file_name = f\"{file_name_without_extension}-cell-{cell_number}.png\"\n",
    "        image_path = dataset_path / classification / f\"{classification}-{new_file_name}\"\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        grayscale_image = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        plt.imsave(str(image_path), grayscale_image, cmap='gray')\n",
    "        print(f\"Saved grayscale image to {image_path}\")\n",
    "\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Cell Classification\")\n",
    "\n",
    "    frame = ttk.Frame(root, padding=\"10\")\n",
    "    frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "\n",
    "    image_label = ttk.Label(frame)\n",
    "    image_label.grid(row=0, column=0, columnspan=3, pady=10)\n",
    "\n",
    "    cell_info_label = ttk.Label(frame, text=\"\")\n",
    "    cell_info_label.grid(row=1, column=0, columnspan=3, pady=5)\n",
    "\n",
    "    current_cell = [0]  # Start from 0 as header is already removed\n",
    "\n",
    "    def resize_image(image_array, target_size=(300, 200)):\n",
    "        img = Image.fromarray(image_array)\n",
    "        img = img.resize(target_size, Image.LANCZOS)\n",
    "        return np.array(img)\n",
    "\n",
    "    def update_image():\n",
    "        if current_cell[0] < len(cell_crops):\n",
    "            resized_img = resize_image(cell_crops[current_cell[0]])\n",
    "            img = ImageTk.PhotoImage(Image.fromarray(resized_img))\n",
    "            image_label.config(image=img)\n",
    "            image_label.image = img  # Keep a reference\n",
    "            cell_info_label.config(text=f\"Cell {current_cell[0] + 1} of {len(cell_crops)}\")\n",
    "        else:\n",
    "            root.destroy()\n",
    "\n",
    "    def on_classification(classification):\n",
    "        save_classified_image(cell_crops[current_cell[0]], classification, current_cell[0] + 1)\n",
    "        current_cell[0] += 1\n",
    "        if current_cell[0] < len(cell_crops):\n",
    "            update_image()\n",
    "        else:\n",
    "            root.destroy()  # Close GUI immediately after classifying the last image\n",
    "\n",
    "    ttk.Button(frame, text=\"TRUE\", command=lambda: on_classification(\"true\")).grid(row=2, column=0, padx=5, pady=10)\n",
    "    ttk.Button(frame, text=\"FALSE\", command=lambda: on_classification(\"false\")).grid(row=2, column=1, padx=5, pady=10)\n",
    "    ttk.Button(frame, text=\"NONE\", command=lambda: on_classification(\"none\")).grid(row=2, column=2, padx=5, pady=10)\n",
    "\n",
    "    update_image()\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extractor\n",
    "#### Function: perform_extraction(image_path)\n",
    "Extracts tables and cells from an image and launches a GUI for cell classification.\n",
    "<br/>\n",
    "<br/>\n",
    "<img src=\"./public/img/CellClassification-GUI.png\" height=\"200\" width=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data for: 20240328_145219.jpg\n",
      "Number of cell crops: 10\n"
     ]
    }
   ],
   "source": [
    "def perform_extraction(image_path):\n",
    "    file_name = image_path.split(\"/\")[-1]\n",
    "    file_name_without_extension = file_name.split(\".\")[0]\n",
    "    print(\"Extracting data for:\", file_name)\n",
    "\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    width, height = image.size\n",
    "    # display(image.resize((int(0.6 * width), (int(0.6 * height)))))\n",
    "\n",
    "    pixel_values = detection_transform(image).unsqueeze(0)\n",
    "    pixel_values = pixel_values.to(\"cpu\")\n",
    "    # print(pixel_values.shape)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(pixel_values)\n",
    "    # print(\"Output shape: \", outputs.logits.shape)\n",
    "\n",
    "    objects = outputs_to_objects(outputs, image.size, id2label)\n",
    "    # print(\"Objects: \", objects)\n",
    "\n",
    "    # fig = visualize_detected_tables(image, objects)\n",
    "    # visualized_image = fig2img(fig)\n",
    "    \n",
    "    # # Prevent image from displaying\n",
    "    # plt.close(fig)\n",
    "\n",
    "    tokens = []\n",
    "    detection_class_thresholds = {\"table\": 0.5, \"table rotated\": 0.5, \"no object\": 10}\n",
    "    crop_padding = 10\n",
    "\n",
    "    tables_crops = objects_to_crops(\n",
    "        image, tokens, objects, detection_class_thresholds, padding=0\n",
    "    )\n",
    "    if len(tables_crops) == 0:\n",
    "        print(\"No tables detected\")\n",
    "        return\n",
    "    cropped_table = tables_crops[0][\"image\"].convert(\"RGB\")\n",
    "    # cropped_table\n",
    "\n",
    "    pixel_values = structure_transform(cropped_table).unsqueeze(0)\n",
    "    pixel_values = pixel_values.to(\"cpu\")\n",
    "    # print(pixel_values.shape)\n",
    "\n",
    "    # forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = structure_model(pixel_values)\n",
    "\n",
    "    # cropped_table_visualized = cropped_table.copy()\n",
    "    # draw = ImageDraw.Draw(cropped_table_visualized)\n",
    "\n",
    "    cells = outputs_to_objects(outputs, cropped_table.size, structure_id2label)\n",
    "    # print(\"Cells: \", cells)\n",
    "\n",
    "    # for cell in cells:\n",
    "    #     draw.rectangle(cell[\"bbox\"], outline=\"red\", width=6)\n",
    "\n",
    "    # cropped_table_visualized\n",
    "\n",
    "    cell_coordinates = get_cell_coordinates_by_row(cells)\n",
    "\n",
    "    # Plotting the cropped cell regions\n",
    "    original_img_np = np.array(cropped_table)\n",
    "    \n",
    "    \n",
    "    # Extract cell crops\n",
    "    cell_crops = []\n",
    "    for i, row in enumerate(cell_coordinates):\n",
    "        if i == 0 and len(cell_coordinates) > 10:  # Skip header if 10 rows or more\n",
    "            continue\n",
    "        last_cell = row[\"cells\"][-1]\n",
    "        cell_x, cell_y, cell_w, cell_h = [int(x) for x in last_cell[\"cell\"]]\n",
    "        cell_crop = original_img_np[cell_y:cell_h, cell_x:cell_w]\n",
    "        cell_crops.append(cell_crop)\n",
    "\n",
    "\n",
    "    # Launch the classification GUI\n",
    "    print(\"Number of cell crops:\", len(cell_crops))\n",
    "    # create_classification_gui(cell_crops, file_name_without_extension)\n",
    "\n",
    "\n",
    "\n",
    "# # Viewing here itself for 1 image\n",
    "# perform_extraction(\"data/Sample_Data/20240328_145219.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runner Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "folder_path = pathlib.Path(\"data/Sample_Data\")\n",
    "\n",
    "for image_path in folder_path.glob(\"*.jpg\"):\n",
    "    image_path = str(image_path).replace(\"\\\\\", \"/\")\n",
    "    print(f\"Reading: {image_path}\")\n",
    "    clear_output(wait=True)\n",
    "    perform_extraction(str(image_path))\n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
